{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24e0faf",
   "metadata": {},
   "source": [
    "# m√¥ h√¨nh catboost ch∆∞a turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e22b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.084924\n",
      "0:\tlearn: 1.3114782\ttotal: 73.6ms\tremaining: 1m 13s\n",
      "100:\tlearn: 0.7065778\ttotal: 6.06s\tremaining: 53.9s\n",
      "200:\tlearn: 0.6278538\ttotal: 12.1s\tremaining: 48.2s\n",
      "300:\tlearn: 0.5602118\ttotal: 18.4s\tremaining: 42.6s\n",
      "400:\tlearn: 0.5035436\ttotal: 24.9s\tremaining: 37.2s\n",
      "500:\tlearn: 0.4546906\ttotal: 31.3s\tremaining: 31.2s\n",
      "600:\tlearn: 0.4158889\ttotal: 37.9s\tremaining: 25.2s\n",
      "700:\tlearn: 0.3815534\ttotal: 49.4s\tremaining: 21.1s\n",
      "800:\tlearn: 0.3489834\ttotal: 56.8s\tremaining: 14.1s\n",
      "900:\tlearn: 0.3214522\ttotal: 1m 3s\tremaining: 7.03s\n",
      "999:\tlearn: 0.2966206\ttotal: 1m 10s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ec3b42f360>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(r'D:\\MINI_Project\\DoAn3\\perdict_train_XGBoost\\students_grading_dataset_clean.csv')\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
    "df.drop(['Student_ID','First_Name','Last_Name','Email','Midterm_Score',\n",
    "         'Final_Score','Projects_Score','Total_Score'],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "# T√°ch X, y\n",
    "X = df.drop('Grade', axis=1)\n",
    "y = df['Grade']\n",
    "\n",
    "# X√°c ƒë·ªãnh c√°c c·ªôt ph√¢n lo·∫°i\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n",
    "#print(\"Categorical features:\", cat_features)\n",
    "\n",
    "# Chia d·ªØ li·ªáu\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"# Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    verbose=0\n",
    ")\"\"\"\n",
    "\"\"\"model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=42,\n",
    "    class_weights=class_weights,\n",
    "    verbose=100\n",
    ")\"\"\"\n",
    "model = CatBoostClassifier(verbose=100) #B·∫Øt ƒë·∫ßu v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh ‚Üí test\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, cat_features=cat_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fc49e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00        32\n",
      "           B       0.60      0.71      0.65       557\n",
      "           C       0.51      0.43      0.47       405\n",
      "           D       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.28      0.29      0.28      1000\n",
      "weighted avg       0.54      0.57      0.55      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MINI_Project\\DoAn3\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MINI_Project\\DoAn3\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MINI_Project\\DoAn3\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# D·ª± ƒëo√°n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ƒê√°nh gi√°\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398e5d9",
   "metadata": {},
   "source": [
    "# m√¥ h√¨nh ƒë√£ ch·ªânh s∆° s∆° c√°c si√™u tham s·ªë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== üìä Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00        31\n",
      "           B       0.61      0.76      0.68       562\n",
      "           C       0.54      0.41      0.46       399\n",
      "           D       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.29      0.29      0.29      1000\n",
      "weighted avg       0.56      0.59      0.57      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1. ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(r'D:\\MINI_Project\\DoAn3\\perdict_train_XGBoost\\students_grading_dataset_clean.csv')\n",
    "\n",
    "# 2. Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
    "df.drop(['Student_ID','First_Name','Last_Name','Email','Midterm_Score',\n",
    "         'Final_Score','Projects_Score','Total_Score'],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "# 3. T√°ch X, y\n",
    "X = df.drop('Grade', axis=1)\n",
    "y = df['Grade']\n",
    "\n",
    "# 4. X√°c ƒë·ªãnh c·ªôt ph√¢n lo·∫°i (categorical)\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# 5. Chia t·∫≠p train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 6. TƒÉng tr·ªçng s·ªë cho c√°c l·ªõp thi·ªÉu s·ªë (Grade A = 0, D = 3 n·∫øu b·∫°n d√πng label encode tr∆∞·ªõc ƒë√≥)\n",
    "# ‚ö†Ô∏è N·∫øu ch∆∞a d√πng LabelEncoder, b·∫°n c√≥ th·ªÉ d√πng map nh∆∞ sau:\n",
    "label_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "y_train = y_train.map(label_map)\n",
    "y_test = y_test.map(label_map)\n",
    "\n",
    "# 7. Thi·∫øt l·∫≠p tr·ªçng s·ªë (class_weights)\n",
    "# Gi√° tr·ªã l·ªõn h∆°n ‚Üí m√¥ h√¨nh h·ªçc k·ªπ h∆°n l·ªõp ƒë√≥\n",
    "class_weights = [5.0, 1.0, 1.0, 10.0]  # A v√† D ƒë∆∞·ª£c ∆∞u ti√™n\n",
    "\n",
    "# 8. Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi si√™u tham s·ªë ƒëi·ªÅu ch·ªânh\n",
    "\n",
    "# Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "# Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,          # S·ªë v√≤ng l·∫∑p (s·ªë c√¢y s·∫Ω x√¢y d·ª±ng). Gi√° tr·ªã c√†ng cao th√¨ m√¥ h√¨nh c√†ng h·ªçc k·ªπ, nh∆∞ng c√≥ nguy c∆° overfit n·∫øu qu√° l·ªõn.\n",
    "    \n",
    "    learning_rate=0.1,       # T·ªëc ƒë·ªô h·ªçc. Gi√° tr·ªã nh·ªè gi√∫p m√¥ h√¨nh h·ªçc t·ª´ t·ª´, ch√≠nh x√°c h∆°n nh∆∞ng c·∫ßn nhi·ªÅu iterations h∆°n. Gi√° tr·ªã l·ªõn h·ªçc nhanh h∆°n nh∆∞ng c√≥ nguy c∆° b·ªè qua th√¥ng tin quan tr·ªçng.\n",
    "    \n",
    "    depth=6,                 # ƒê·ªô s√¢u c·ªßa m·ªói c√¢y quy·∫øt ƒë·ªãnh. ƒê·ªô s√¢u cao gi√∫p m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c quan h·ªá ph·ª©c t·∫°p nh∆∞ng d·ªÖ b·ªã overfit. Th∆∞·ªùng ch·ªçn t·ª´ 4 ƒë·∫øn 10.\n",
    "    \n",
    "    verbose=0,               # Kh√¥ng hi·ªÉn th·ªã log trong qu√° tr√¨nh hu·∫•n luy·ªán (0 = im l·∫∑ng, 100 = hi·ªÉn th·ªã m·ªói 100 v√≤ng l·∫∑p, v.v.). N·∫øu b·∫°n mu·ªën theo d√µi ti·∫øn tr√¨nh, h√£y ƒë·ªïi th√†nh `verbose=100`.\n",
    "    \n",
    "    class_weights=class_weights  # Danh s√°ch tr·ªçng s·ªë cho t·ª´ng l·ªõp. D√πng ƒë·ªÉ x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu. L·ªõp √≠t m·∫´u n√™n c√≥ tr·ªçng s·ªë cao h∆°n ƒë·ªÉ m√¥ h√¨nh ∆∞u ti√™n h·ªçc.\n",
    ")\n",
    "\n",
    "\n",
    "# 9. Fit model\n",
    "model.fit(X_train, y_train, cat_features=cat_features)\n",
    "\n",
    "# 10. D·ª± ƒëo√°n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 11. B√°o c√°o k·∫øt qu·∫£\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['A', 'B', 'C', 'D']\n",
    "print(\"\\n=== üìä Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56677585",
   "metadata": {},
   "source": [
    "# tuning si√™u tham s·ªë cho m√¥ h√¨nh CatBoostRegressor b·∫±ng RandomizedSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0fa600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up grind Search Functions\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import max_error, r2_score, root_mean_squared_error, mean_absolute_error, max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5576115c",
   "metadata": {},
   "source": [
    "## h√†m ƒë√°nh gi√° m√¥ h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40782899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"=== üìä Evaluation Report ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['A', 'B', 'C', 'D']))\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334e0d5",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV ƒë·ªÉ ch·ªçn si√™u tham s·ªë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f3c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def randomized_search_catboost(X_train, y_train, categorical_features):\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function='MultiClass',\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "        class_weights=[5.0, 1.0, 1.0, 10.0]  # C√¢n b·∫±ng l·ªõp\n",
    "    )\n",
    "\n",
    "    # T·∫≠p si√™u tham s·ªë c·∫ßn th·ª≠\n",
    "    param_grid = {\n",
    "        'iterations': [100, 300, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'depth': [4, 6, 8, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7],\n",
    "        'border_count': [32, 64, 128]\n",
    "    }\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,  # th·ª≠ 20 t·ªï h·ª£p ng·∫´u nhi√™n\n",
    "        scoring='f1_weighted',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train, cat_features=categorical_features)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 1. ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(r'D:\\MINI_Project\\DoAn3\\perdict_train_XGBoost\\students_grading_dataset_clean.csv')\n",
    "\n",
    "# 2. Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
    "df.drop(['Student_ID', 'First_Name', 'Last_Name', 'Email',\n",
    "         'Midterm_Score', 'Final_Score', 'Projects_Score', 'Total_Score'],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "# 3. T√°ch X, y\n",
    "X = df.drop('Grade', axis=1)\n",
    "y = df['Grade']\n",
    "\n",
    "# 4. X√°c ƒë·ªãnh c·ªôt ph√¢n lo·∫°i (categorical)\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# 5. Encode label (n·∫øu c·∫ßn)\n",
    "label_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "y = y.map(label_map)\n",
    "\n",
    "# 6. Chia t·∫≠p train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 7. Thi·∫øt l·∫≠p tr·ªçng s·ªë (class_weights)\n",
    "# Gi√° tr·ªã l·ªõn h∆°n ‚Üí m√¥ h√¨nh h·ªçc k·ªπ h∆°n l·ªõp ƒë√≥\n",
    "#class_weights = [5.0, 1.0, 1.0, 10.0]  # A v√† D ƒë∆∞·ª£c ∆∞u ti√™n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee45859",
   "metadata": {},
   "source": [
    "## G·ªçi v√† hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c59a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "=== üìä Evaluation Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00        31\n",
      "           B       0.62      0.77      0.69       562\n",
      "           C       0.55      0.42      0.48       399\n",
      "           D       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.29      0.30      0.29      1000\n",
      "weighted avg       0.57      0.60      0.58      1000\n",
      "\n",
      "\n",
      "‚úÖ Best Hyperparameters: {'learning_rate': 0.05, 'l2_leaf_reg': 5, 'iterations': 100, 'depth': 6, 'border_count': 128}\n",
      "üéØ Accuracy: 0.6010, F1-score: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MINI_Project\\DoAn3\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MINI_Project\\DoAn3\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MINI_Project\\DoAn3\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# T√¨m m√¥ h√¨nh t·ªët nh·∫•t\n",
    "best_model, best_params = randomized_search_catboost(X_train, y_train, cat_features)\n",
    "\n",
    "# ƒê√°nh gi√° m√¥ h√¨nh t·ªët nh·∫•t\n",
    "\n",
    "accuracy, f1 = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "print(\"\\n‚úÖ Best Hyperparameters:\", best_params)\n",
    "print(f\"üéØ Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2361a7",
   "metadata": {},
   "source": [
    "## t·∫°o ra c·ªôt m·ªõi t√™n l√† at_risk, d√πng ƒë·ªÉ g·∫Øn nh√£n h·ªçc sinh c√≥ nguy c∆° h·ªçc y·∫øu.\n",
    "\n",
    "## H·ªçc sinh n√†o c√≥ Grade l√† 'C' ho·∫∑c 'D' th√¨ ƒë∆∞·ª£c g√°n nh√£n l√† 1 (c√≥ nguy c∆°), c√≤n l·∫°i l√† 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e49872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(r'D:\\MINI_Project\\DoAn3\\perdict_train_XGBoost\\students_grading_dataset_clean.csv')\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
    "df.drop(['Student_ID','First_Name','Last_Name','Email','Midterm_Score',\n",
    "         'Final_Score','Projects_Score','Total_Score'], axis=1, inplace=True)\n",
    "\n",
    "# T·∫°o nh√£n m·ª•c ti√™u 'at_risk' n·∫øu Grade l√† C ho·∫∑c D\n",
    "df['at_risk'] = df['Grade'].apply(lambda x: 1 if x in ['C', 'D'] else 0)\n",
    "\n",
    "# X√≥a c·ªôt Grade ƒë·ªÉ tr√°nh r√≤ r·ªâ d·ªØ li·ªáu\n",
    "df.drop('Grade', axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670613fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. M√£ h√≥a c√°c c·ªôt d·∫°ng object ===\n",
    "encoders = {}\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    encoders[col] = le  # l∆∞u l·∫°i ƒë·ªÉ d√πng cho Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72a7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia X, y\n",
    "X = df.drop(columns='at_risk')\n",
    "y = df['at_risk']\n",
    "\n",
    "# M√£ h√≥a c√°c c·ªôt d·∫°ng object n·∫øu c√≥\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "# Chia t·∫≠p train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc19ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"üìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(f\"‚úÖ Accuracy: {acc:.4f} | F1-score: {f1:.4f}\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4fd9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "üìä Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.74       592\n",
      "           1       0.61      0.43      0.51       408\n",
      "\n",
      "    accuracy                           0.66      1000\n",
      "   macro avg       0.64      0.62      0.62      1000\n",
      "weighted avg       0.65      0.66      0.64      1000\n",
      "\n",
      "‚úÖ Accuracy: 0.6570 | F1-score: 0.5051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.657, 0.5050505050505051)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o m√¥ h√¨nh CatBoost\n",
    "cat_model = CatBoostClassifier(verbose=0, random_seed=42)\n",
    "\n",
    "# Si√™u tham s·ªë c·∫ßn t√¨m ki·∫øm\n",
    "param_dist = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    'iterations': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# T√¨m ki·∫øm ng·∫´u nhi√™n\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=cat_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Hu·∫•n luy·ªán\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# ƒê√°nh gi√°\n",
    "best_model = random_search.best_estimator_\n",
    "evaluate_model(best_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02674318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73       592\n",
      "           1       0.60      0.45      0.51       408\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.64      0.62      0.62      1000\n",
      "weighted avg       0.65      0.65      0.64      1000\n",
      "\n",
      "Accuracy: 0.65, F1: 0.51\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv('students_grading_dataset_clean.csv')\n",
    "\n",
    "# X√≥a c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
    "df.drop(['Student_ID', 'First_Name', 'Last_Name', 'Email',\n",
    "         'Midterm_Score', 'Final_Score', 'Projects_Score', 'Total_Score'], axis=1, inplace=True)\n",
    "\n",
    "# T·∫°o bi·∫øn m·ª•c ti√™u 'at_risk': n·∫øu Grade l√† C ho·∫∑c D th√¨ 1, ng∆∞·ª£c l·∫°i l√† 0\n",
    "df['at_risk'] = df['Grade'].apply(lambda x: 1 if x in ['C', 'D'] else 0)\n",
    "\n",
    "# X√≥a c·ªôt Grade ƒë·ªÉ tr√°nh r√≤ r·ªâ d·ªØ li·ªáu\n",
    "df.drop('Grade', axis=1, inplace=True)\n",
    "\n",
    "# X t√°ch ƒë·∫∑c tr∆∞ng, y l√† nh√£n\n",
    "X = df.drop(columns='at_risk')\n",
    "y = df['at_risk']\n",
    "\n",
    "# M√£ h√≥a nh√£n\n",
    "label_encoders = {}\n",
    "class_mappings = {}\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n",
    "    class_mappings[col] = list(le.classes_)\n",
    "\n",
    "# L∆∞u l·∫°i label_encoders v√† class_mappings ƒë·ªÉ d√πng cho Streamlit\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "joblib.dump(class_mappings, 'class_mappings.pkl')\n",
    "\n",
    "# Chia train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kh·ªüi t·∫°o m√¥ h√¨nh CatBoost\n",
    "model = CatBoostClassifier(verbose=0, random_seed=42)\n",
    "\n",
    "# Si√™u tham s·ªë\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    'iterations': [100, 200, 300]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(model, params, n_iter=10, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# M√¥ h√¨nh t·ªët nh·∫•t\n",
    "best_model = search.best_estimator_\n",
    "joblib.dump(best_model, 'catboost_model.pkl')\n",
    "\n",
    "# ƒê√°nh gi√°\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}, F1: {f1_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738ef8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "üéØ Best Parameters: {'learning_rate': 0.1, 'l2_leaf_reg': 5, 'iterations': 300, 'depth': 4, 'border_count': 128}\n",
      "‚úÖ Accuracy: 0.597\n",
      "‚úÖ F1 Score (weighted): 0.579\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1. ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(r'D:\\MINI_Project\\DoAn3\\perdict_train_XGBoost\\students_grading_dataset_clean.csv')\n",
    "\n",
    "# 2. Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
    "df.drop(['Student_ID', 'First_Name', 'Last_Name', 'Email',\n",
    "         'Midterm_Score', 'Final_Score', 'Projects_Score', 'Total_Score'],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "# 3. T√°ch X, y\n",
    "X = df.drop('Grade', axis=1)\n",
    "y = df['Grade']\n",
    "\n",
    "# 4. X√°c ƒë·ªãnh c·ªôt ph√¢n lo·∫°i (categorical)\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# 5. Encode nh√£n ƒë·∫ßu ra (grade)\n",
    "label_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "y = y.map(label_map)\n",
    "\n",
    "# 6. Chuy·ªÉn ƒë·ªïi bi·∫øn ph√¢n lo·∫°i sang ki·ªÉu chu·ªói (b·∫Øt bu·ªôc v·ªõi CatBoost)\n",
    "X[cat_features] = X[cat_features].astype(str)\n",
    "\n",
    "# 7. Chia d·ªØ li·ªáu train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 8. ƒê·ªãnh nghƒ©a h√†m t√¨m si√™u tham s·ªë\n",
    "def randomized_search_catboost(X_train, y_train, categorical_features):\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function='MultiClass',\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "        class_weights=[5.0, 1.0, 1.0, 10.0]  # ∆Øu ti√™n l·ªõp A v√† D\n",
    "    )\n",
    "\n",
    "    # T·∫≠p h·ª£p si√™u tham s·ªë\n",
    "    param_grid = {\n",
    "        'iterations': [100, 300, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'depth': [4, 6, 8, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7],\n",
    "        'border_count': [32, 64, 128]\n",
    "    }\n",
    "\n",
    "    # T√¨m ki·∫øm ng·∫´u nhi√™n\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,\n",
    "        scoring='f1_weighted',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Hu·∫•n luy·ªán v√† truy·ªÅn c·ªôt ph√¢n lo·∫°i\n",
    "    random_search.fit(X_train, y_train, cat_features=categorical_features)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# 9. G·ªçi h√†m ƒë·ªÉ t√¨m m√¥ h√¨nh t·ªët nh·∫•t\n",
    "best_model, best_params = randomized_search_catboost(X_train, y_train, cat_features)\n",
    "\n",
    "# 10. D·ª± ƒëo√°n v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\nüéØ Best Parameters:\", best_params)\n",
    "print(\"‚úÖ Accuracy:\", round(accuracy, 4))\n",
    "print(\"‚úÖ F1 Score (weighted):\", round(f1, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32927f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
